{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srijoy18/PRO/blob/main/Copy_of_Credit_Risk_Part_1_Probability_of_Default_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "devanshi23_loan_data_2007_2014_path = kagglehub.dataset_download('devanshi23/loan-data-2007-2014')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "iH92AOEFVffz"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context & Objective:\n",
        "\n",
        "The dataset being used here has 7 years' historical loan data taken from [LendingClub](https://www.lendingclub.com/). By looking at the loan status, we can check if the loan was sanctioned to the customers or not. If the loan status is \"charged off\" or \"default\" or the issuance of loan got delayed by 31-120 days, it is a bad loan. We will analyze the characteristics of the customers whose loans belong to **\"bad loan\"** category and will build a **Probability of Default (PD) Model**, so that is can be used in future to predict the customer will default or not.\n",
        "\n",
        "We have used some useful concepts:\n",
        "- Binning,\n",
        "- Weight of Evidence (WoE),\n",
        "- Information Value (IV)\n",
        "\n",
        "**Acknowledgements:**\n",
        "- Some insightful kernels which discussed the above three topics earlier for other applications are: [Pranav Pandya's work](https://www.kaggle.com/code/pranav84/talkingdata-with-breaking-bad-feature-engg/report), [Bryan Arnold's work](https://www.kaggle.com/code/puremath86/iv-woe-starter-for-python/notebook)\n",
        "- [This youtube webinar](https://www.youtube.com/watch?v=fiQhxn9RjEQ&t=2873s) on credit risk analysis is also informative"
      ],
      "metadata": {
        "id": "A-6qNo7lVff1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(context='notebook')\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "plt.tight_layout()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-05-05T11:38:28.924086Z",
          "iopub.execute_input": "2022-05-05T11:38:28.924857Z",
          "iopub.status.idle": "2022-05-05T11:38:30.044721Z",
          "shell.execute_reply.started": "2022-05-05T11:38:28.924738Z",
          "shell.execute_reply": "2022-05-05T11:38:30.043863Z"
        },
        "trusted": true,
        "id": "o2SP9x5OVff2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(r'../input/loan-data-2007-2014/loan_data_2007_2014/loan_data_2007_2014.csv')"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-05-05T11:38:33.964014Z",
          "iopub.execute_input": "2022-05-05T11:38:33.964328Z",
          "iopub.status.idle": "2022-05-05T11:38:42.37043Z",
          "shell.execute_reply.started": "2022-05-05T11:38:33.964292Z",
          "shell.execute_reply": "2022-05-05T11:38:42.369588Z"
        },
        "trusted": true,
        "id": "zNTRsqUkVff2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Description & Business Interpretation of the Features"
      ],
      "metadata": {
        "id": "iWslyNjiVff2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check number of columns and data types of features\n",
        "\n",
        "data.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:33:15.486464Z",
          "iopub.execute_input": "2022-04-21T16:33:15.486753Z",
          "iopub.status.idle": "2022-04-21T16:33:16.638961Z",
          "shell.execute_reply.started": "2022-04-21T16:33:15.48672Z",
          "shell.execute_reply": "2022-04-21T16:33:16.637714Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "YWiLcQ0YVff2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the \"instance attribute summary\" section in this [webpage](https://www.rubydoc.info/gems/lending_club/0.0.2/LendingClub/Loan)"
      ],
      "metadata": {
        "id": "HbUSL6v3Vff3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assigning the Target Column to Identify Bad Loans"
      ],
      "metadata": {
        "id": "oEeARU4rVff3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column based on the loan_status column that will be our target variable\n",
        "data['bad_loan'] = np.where(data.loc[:, 'loan_status'].isin(['Charged Off', 'Default', 'Late (31-120 days)',\n",
        "                                        'Does not meet the credit policy. Status:Charged Off']), 0, 1)\n",
        "# Drop the original 'loan_status' column\n",
        "data.drop(columns = ['loan_status'], inplace = True)\n",
        "data.drop('Unnamed: 0', inplace=True, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-05T11:38:50.886552Z",
          "iopub.execute_input": "2022-05-05T11:38:50.887454Z",
          "iopub.status.idle": "2022-05-05T11:38:51.297566Z",
          "shell.execute_reply.started": "2022-05-05T11:38:50.887397Z",
          "shell.execute_reply": "2022-05-05T11:38:51.296766Z"
        },
        "trusted": true,
        "id": "1mF6a98pVff3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('bad_loan', axis = 1)\n",
        "y = data['bad_loan']"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-05-05T11:38:57.324884Z",
          "iopub.execute_input": "2022-05-05T11:38:57.325447Z",
          "iopub.status.idle": "2022-05-05T11:38:57.478719Z",
          "shell.execute_reply.started": "2022-05-05T11:38:57.32541Z",
          "shell.execute_reply": "2022-05-05T11:38:57.47791Z"
        },
        "trusted": true,
        "id": "HliEMmc2Vff3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display some\n",
        "data.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:33:34.645985Z",
          "iopub.execute_input": "2022-04-21T16:33:34.646348Z",
          "iopub.status.idle": "2022-04-21T16:33:34.693477Z",
          "shell.execute_reply.started": "2022-04-21T16:33:34.646316Z",
          "shell.execute_reply": "2022-04-21T16:33:34.692352Z"
        },
        "_kg_hide-input": false,
        "trusted": true,
        "id": "5QHEuAsQVff4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cols that have > 70% missing values\n",
        "missing_values = data.isnull().mean()\n",
        "missing_values[missing_values>0.7]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:33:40.897696Z",
          "iopub.execute_input": "2022-04-21T16:33:40.898017Z",
          "iopub.status.idle": "2022-04-21T16:33:41.972937Z",
          "shell.execute_reply.started": "2022-04-21T16:33:40.897978Z",
          "shell.execute_reply": "2022-04-21T16:33:41.971741Z"
        },
        "trusted": true,
        "id": "hfK2p2klVff4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing:\n",
        "\n",
        "* We need to drop the columns having > 70% missing values.\n",
        "\n",
        "* The follwing features are identifiers and can not be used in building model. id, member id, url, title, desc, zipcode and emp_title\n",
        "\n",
        "* The sub_grade column wll also be droped as it contains the same information as the grade columns.\n",
        "\n",
        "* Features that contain information about the future will not be included in building the model since those events are yet to occur. The features include next_pymnt_d, recoveries, collection_recovery_fee, total_rec_prncp and total_rec_late_fee"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-16T18:23:36.569209Z",
          "iopub.execute_input": "2022-04-16T18:23:36.569514Z",
          "iopub.status.idle": "2022-04-16T18:23:36.577464Z",
          "shell.execute_reply.started": "2022-04-16T18:23:36.56948Z",
          "shell.execute_reply": "2022-04-16T18:23:36.575967Z"
        },
        "id": "BuKHjvcbVff4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping irrelevant cols & cols with missing values\n",
        "\n",
        "columns_to_drop = ['id', 'member_id', 'sub_grade', 'emp_title', 'url', 'desc', 'title', 'zip_code', 'next_pymnt_d',\n",
        "                  'recoveries', 'collection_recovery_fee', 'total_rec_prncp', 'total_rec_late_fee', 'desc', 'mths_since_last_record',\n",
        "                  'mths_since_last_major_derog', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'open_acc_6m', 'open_il_6m',\n",
        "                  'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m',\n",
        "                  'max_bal_bc', 'all_util', 'inq_fi', 'total_cu_tl', 'inq_last_12m','policy_code',]\n",
        "data.drop(columns=columns_to_drop, inplace=True, axis=1)\n",
        "\n",
        "data.dropna(inplace=True)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-05-05T11:39:08.094578Z",
          "iopub.execute_input": "2022-05-05T11:39:08.095015Z",
          "iopub.status.idle": "2022-05-05T11:39:08.996409Z",
          "shell.execute_reply.started": "2022-05-05T11:39:08.094977Z",
          "shell.execute_reply": "2022-05-05T11:39:08.995459Z"
        },
        "trusted": true,
        "id": "vdpUwjaZVff4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking Correlation among Features"
      ],
      "metadata": {
        "id": "FMNzt6LHVff4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation matrix with correlation co-effiecients\n",
        "import numpy as np\n",
        "mask = np.zeros_like(data.corr().fillna(0), dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "plt.figure(figsize=(24,24))\n",
        "sns.heatmap(data.corr(), mask=mask, annot=True,  cmap=\"inferno\", vmin = -1, fmt='.1g', edgecolor='w', linewidth=0.6)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-05-05T11:40:11.247164Z",
          "iopub.execute_input": "2022-05-05T11:40:11.247483Z",
          "iopub.status.idle": "2022-05-05T11:40:14.473616Z",
          "shell.execute_reply.started": "2022-05-05T11:40:11.247448Z",
          "shell.execute_reply": "2022-05-05T11:40:14.472699Z"
        },
        "trusted": true,
        "id": "mfDJafoZVff4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Multicolliear Features"
      ],
      "metadata": {
        "id": "vj5uFN1RVff5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " data.drop(columns=['loan_amnt', 'revol_bal', 'funded_amnt', 'funded_amnt_inv', 'installment',\n",
        "                   'total_pymnt_inv',  'out_prncp_inv',  'total_acc'], inplace=True)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-05-05T11:40:55.125204Z",
          "iopub.execute_input": "2022-05-05T11:40:55.125946Z",
          "iopub.status.idle": "2022-05-05T11:40:55.163135Z",
          "shell.execute_reply.started": "2022-05-05T11:40:55.125903Z",
          "shell.execute_reply": "2022-05-05T11:40:55.16227Z"
        },
        "trusted": true,
        "id": "VDrKjc0PVff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "mask = np.zeros_like(data.corr().fillna(0), dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "plt.figure(figsize=(24,24))\n",
        "sns.heatmap(data.corr(), mask=mask, annot=True,  cmap=\"inferno\", vmin = -1, fmt='.1g', edgecolor='w', linewidth=0.6)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2022-05-05T11:41:23.204533Z",
          "iopub.execute_input": "2022-05-05T11:41:23.204812Z",
          "iopub.status.idle": "2022-05-05T11:41:25.175115Z",
          "shell.execute_reply.started": "2022-05-05T11:41:23.204782Z",
          "shell.execute_reply": "2022-05-05T11:41:25.174Z"
        },
        "trusted": true,
        "id": "71EVAO29Vff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##descriptive statistics\n",
        "data.describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:35:54.839608Z",
          "iopub.execute_input": "2022-04-21T16:35:54.841009Z",
          "iopub.status.idle": "2022-04-21T16:35:55.089037Z",
          "shell.execute_reply.started": "2022-04-21T16:35:54.840937Z",
          "shell.execute_reply": "2022-04-21T16:35:55.087739Z"
        },
        "trusted": true,
        "id": "og4DO5jDVff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Type Transformation"
      ],
      "metadata": {
        "id": "up07maG3Vff5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check datatypes of data again\n",
        "\n",
        "data.info()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:04.126358Z",
          "iopub.execute_input": "2022-04-21T16:36:04.126695Z",
          "iopub.status.idle": "2022-04-21T16:36:04.424086Z",
          "shell.execute_reply.started": "2022-04-21T16:36:04.126639Z",
          "shell.execute_reply": "2022-04-21T16:36:04.423188Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "tJK6ytaiVff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following variables are not possessing appropriate data types and should be modified. Also the NaN values should be replaced with zeroes wherever applicable.\n",
        "\n",
        "- emp_length,\n",
        "- term,\n",
        "- issue_d,\n",
        "- last_pymnt_d,\n",
        "- last_credit_pull_d\n",
        "- earliest_cr_line\n",
        "\n",
        "We will define functions to transform their data types."
      ],
      "metadata": {
        "id": "dEx30Wa8Vff5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting emp_length to numeric and assign NaN to zero\n",
        "\n",
        "def emp_length_convert(df, column):\n",
        "    df[column] = df[column].str.replace('\\+ years', '')\n",
        "    df[column] = df[column].str.replace('< 1 year', str(0))\n",
        "    df[column] = df[column].str.replace(' years', '')\n",
        "    df[column] = df[column].str.replace(' year', '')\n",
        "    df[column] = pd.to_numeric(df[column])\n",
        "    df[column].fillna(value = 0, inplace = True)\n",
        "\n",
        "\n",
        "emp_length_convert(data, 'emp_length')\n",
        "\n",
        "data['emp_length'].unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:12.761997Z",
          "iopub.execute_input": "2022-04-21T16:36:12.762767Z",
          "iopub.status.idle": "2022-04-21T16:36:13.590293Z",
          "shell.execute_reply.started": "2022-04-21T16:36:12.762726Z",
          "shell.execute_reply": "2022-04-21T16:36:13.58938Z"
        },
        "trusted": true,
        "id": "ujiPzI0vVff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['emp_length'].dtype"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:16.551453Z",
          "iopub.execute_input": "2022-04-21T16:36:16.55183Z",
          "iopub.status.idle": "2022-04-21T16:36:16.559559Z",
          "shell.execute_reply.started": "2022-04-21T16:36:16.551794Z",
          "shell.execute_reply": "2022-04-21T16:36:16.558363Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "O5lvySZzVff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting term to numeric\n",
        "\n",
        "def term_numeric(df, column):\n",
        "    df[column] = pd.to_numeric(df[column].str.replace(' months', ''))\n",
        "\n",
        "term_numeric(data, 'term')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:23.69927Z",
          "iopub.execute_input": "2022-04-21T16:36:23.700234Z",
          "iopub.status.idle": "2022-04-21T16:36:24.073796Z",
          "shell.execute_reply.started": "2022-04-21T16:36:23.700178Z",
          "shell.execute_reply": "2022-04-21T16:36:24.072753Z"
        },
        "trusted": true,
        "id": "R4LhhwahVff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['term'].dtype"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:26.637529Z",
          "iopub.execute_input": "2022-04-21T16:36:26.637943Z",
          "iopub.status.idle": "2022-04-21T16:36:26.64554Z",
          "shell.execute_reply.started": "2022-04-21T16:36:26.637884Z",
          "shell.execute_reply": "2022-04-21T16:36:26.644445Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "J26Z52-DVff5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing date cols\n",
        "\n",
        "def date_columns(df, column):\n",
        "    # store current month\n",
        "    today_date = pd.to_datetime('2020-08-01')\n",
        "    # convert to datetime format\n",
        "    df[column] = pd.to_datetime(df[column], format = \"%b-%y\")\n",
        "    # calculate the difference in months and add to a new column\n",
        "    df['mths_since_' + column] = round(pd.to_numeric((today_date - df[column]) / np.timedelta64(1, 'M')))\n",
        "    # make any resulting -ve values to be equal to the max date\n",
        "    df['mths_since_' + column] = df['mths_since_' + column].apply(lambda x: df['mths_since_' + column].max() if x < 0 else x)\n",
        "    # drop the original date column\n",
        "    df.drop(columns = [column], inplace = True)\n",
        "\n",
        "\n",
        "date_columns(data, 'issue_d')\n",
        "date_columns(data, 'last_pymnt_d')\n",
        "date_columns(data, 'last_credit_pull_d')\n",
        "date_columns(data, 'earliest_cr_line')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:34.182155Z",
          "iopub.execute_input": "2022-04-21T16:36:34.182829Z",
          "iopub.status.idle": "2022-04-21T16:36:35.159174Z",
          "shell.execute_reply.started": "2022-04-21T16:36:34.182775Z",
          "shell.execute_reply": "2022-04-21T16:36:35.158469Z"
        },
        "trusted": true,
        "id": "-mYe_FfaVff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for missing values again\n",
        "\n",
        "missing_values = data.isnull().sum()\n",
        "missing_values[missing_values>0]/len(data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:41.379844Z",
          "iopub.execute_input": "2022-04-21T16:36:41.380561Z",
          "iopub.status.idle": "2022-04-21T16:36:41.559233Z",
          "shell.execute_reply.started": "2022-04-21T16:36:41.3805Z",
          "shell.execute_reply": "2022-04-21T16:36:41.558289Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "_GZwqT21Vff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seperating categorical features from numerical\n",
        "categorical_features = data.select_dtypes(exclude='number')\n",
        "numerical_features = data.select_dtypes(exclude='object')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:36:52.980119Z",
          "iopub.execute_input": "2022-04-21T16:36:52.980644Z",
          "iopub.status.idle": "2022-04-21T16:36:53.024162Z",
          "shell.execute_reply.started": "2022-04-21T16:36:52.980609Z",
          "shell.execute_reply": "2022-04-21T16:36:53.023412Z"
        },
        "trusted": true,
        "id": "hRPNmPVVVff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to dataframe\n",
        "filled_data = data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:37:22.258214Z",
          "iopub.execute_input": "2022-04-21T16:37:22.258835Z",
          "iopub.status.idle": "2022-04-21T16:37:22.29824Z",
          "shell.execute_reply.started": "2022-04-21T16:37:22.258796Z",
          "shell.execute_reply": "2022-04-21T16:37:22.297365Z"
        },
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "id": "irKAZIBiVff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_data = data\n",
        "\n",
        "#checking for any missing values\n",
        "missing = preprocess_data.isnull().sum()\n",
        "missing[missing>0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:37:29.436994Z",
          "iopub.execute_input": "2022-04-21T16:37:29.43761Z",
          "iopub.status.idle": "2022-04-21T16:37:29.611613Z",
          "shell.execute_reply.started": "2022-04-21T16:37:29.437571Z",
          "shell.execute_reply": "2022-04-21T16:37:29.610949Z"
        },
        "trusted": true,
        "id": "M6p5AWRjVff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally no missing values"
      ],
      "metadata": {
        "id": "42Yyc0leVff6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Binning, Weight of Evidence (WoE), Information Value (IV)\n",
        "\n",
        "- **Binning** create buckets of independent variables based on ranking  methods. Binning helps us converting continuous variables into categorical ones. This process allows us to understand feature performance better. The  insights from this part of the analysis can be useful in devising portfolio risk strategies. One simple binning example using \"age\" is given below for illustration.\n",
        "![image.png](attachment:bdbdc913-4c0a-4c82-a1ab-8850d4080bd4.png)\n",
        "\n",
        "- **Weight of Evidence (WoE)** will help us to determine which categories should be binned together. WOE measures the strength of a bin in differentiating the Good and Bad accounts. WOE < 0 indicates that the variable bin is captures higher proportion of bad accounts.\n",
        "\n",
        "\n",
        "- **Information Value (IV)** will help in determining which variables are useful for prediction in the logistic regression model. IV is the measure of overall predictive power of the variables and is very useful for feature selection.\n",
        "\n",
        "The formulae of WoE and IV are as follows:\n",
        "\n",
        "![image.png](attachment:21787bf9-6abd-4c74-a2dc-1d6594d13625.png)"
      ],
      "metadata": {
        "id": "l8REHSOZVff6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to calculate Weight of Evidence (WoE) and Information Value (IV)\n",
        "\n",
        "def iv_woe(data, target, bins=10, show_woe=False):\n",
        "\n",
        "    newDF,woeDF = pd.DataFrame(), pd.DataFrame()\n",
        "    cols = data.columns\n",
        "\n",
        "    #Run WoE and IV on all the independent variables\n",
        "    for ivars in cols[~cols.isin([target])]:\n",
        "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars]))>10):\n",
        "            binned_x = pd.qcut(data[ivars], bins,  duplicates='drop')\n",
        "            d0 = pd.DataFrame({'x': binned_x, 'y': data[target]})\n",
        "        else:\n",
        "            d0 = pd.DataFrame({'x': data[ivars], 'y': data[target]})\n",
        "        d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
        "        d.columns = ['Cutoff', 'N', 'Events']\n",
        "        d['% of Events'] = np.maximum(d['Events'], 0.5) / d['Events'].sum()\n",
        "        d['Non-Events'] = d['N'] - d['Events']\n",
        "        d['% of Non-Events'] = np.maximum(d['Non-Events'], 0.5) / d['Non-Events'].sum()\n",
        "        d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
        "        d['IV'] = d['WoE'] * (d['% of Events'] - d['% of Non-Events'])\n",
        "        d.insert(loc=0, column='Variable', value=ivars)\n",
        "        print(\"Information value of \" + ivars + \" is \" + str(round(d['IV'].sum(),6)))\n",
        "        temp =pd.DataFrame({\"Variable\" : [ivars], \"IV\" : [d['IV'].sum()]}, columns = [\"Variable\", \"IV\"])\n",
        "        newDF=pd.concat([newDF,temp], axis=0)\n",
        "        woeDF=pd.concat([woeDF,d], axis=0)\n",
        "\n",
        "        if show_woe == True:\n",
        "            print(d)\n",
        "\n",
        "    return newDF, woeDF\n",
        "\n",
        "iv, woe = iv_woe(preprocess_data, target='bad_loan', bins=20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:37:41.412066Z",
          "iopub.execute_input": "2022-04-21T16:37:41.412735Z",
          "iopub.status.idle": "2022-04-21T16:37:42.855821Z",
          "shell.execute_reply.started": "2022-04-21T16:37:41.412684Z",
          "shell.execute_reply": "2022-04-21T16:37:42.854916Z"
        },
        "trusted": true,
        "id": "FIEtVCa6Vff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rule of thumb says that all variables with IV < 0.02 are not useful for prediction and IV > 0.5 have a suspicious predictive power. Therefore, the follwing variables will not be included out_prncp, last_pymnt_amnt, delinq_2yrs, mths_since_last_delinq, open_acc, pub_rec, total_acc, collections_12_mths_ex_med, acc_now_delinq, tot_coll_amt and mths_since_last_pymnt_d"
      ],
      "metadata": {
        "id": "9BSxfHt1Vff6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drop columns with low IV\n",
        "preprocess_data.drop(columns=[ 'pymnt_plan', 'last_pymnt_amnt', 'revol_util', 'delinq_2yrs', 'mths_since_last_delinq',\n",
        "                              'open_acc', 'pub_rec',  'collections_12_mths_ex_med', 'acc_now_delinq',\n",
        "                              'tot_coll_amt', 'mths_since_last_pymnt_d', 'emp_length', 'application_type'], axis=1, inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:37:50.840896Z",
          "iopub.execute_input": "2022-04-21T16:37:50.841207Z",
          "iopub.status.idle": "2022-04-21T16:37:50.864463Z",
          "shell.execute_reply.started": "2022-04-21T16:37:50.841171Z",
          "shell.execute_reply": "2022-04-21T16:37:50.863365Z"
        },
        "trusted": true,
        "id": "bGyHTnEuVff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy variables for cat cols\n",
        "data_dummies1 = [pd.get_dummies(preprocess_data['grade'], prefix='grade', prefix_sep=':'),\n",
        "                 pd.get_dummies(preprocess_data['home_ownership'], prefix='home_ownership', prefix_sep=':'),\n",
        "                 pd.get_dummies(preprocess_data['verification_status'], prefix='verification_status', prefix_sep=':'),\n",
        "                 pd.get_dummies(preprocess_data['purpose'], prefix='purpose', prefix_sep=':'),\n",
        "                 pd.get_dummies(preprocess_data['addr_state'], prefix='addr_state', prefix_sep=':'),\n",
        "                 pd.get_dummies(preprocess_data['initial_list_status'], prefix='initial_list_status', prefix_sep=':')\n",
        "                ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:37:59.058564Z",
          "iopub.execute_input": "2022-04-21T16:37:59.059334Z",
          "iopub.status.idle": "2022-04-21T16:37:59.245243Z",
          "shell.execute_reply.started": "2022-04-21T16:37:59.059262Z",
          "shell.execute_reply": "2022-04-21T16:37:59.24393Z"
        },
        "trusted": true,
        "id": "560lA7pqVff7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn  data_dummies into dataframe\n",
        "\n",
        "categorical_dummies = pd.concat(data_dummies1, axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:38:05.893659Z",
          "iopub.execute_input": "2022-04-21T16:38:05.894019Z",
          "iopub.status.idle": "2022-04-21T16:38:05.929066Z",
          "shell.execute_reply.started": "2022-04-21T16:38:05.893982Z",
          "shell.execute_reply": "2022-04-21T16:38:05.927931Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "7pI7kWxtVff7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatinating preprocess_data with categorical_dummies\n",
        "\n",
        "preprocess_data = pd.concat([preprocess_data, categorical_dummies], axis=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:38:17.959388Z",
          "iopub.execute_input": "2022-04-21T16:38:17.959798Z",
          "iopub.status.idle": "2022-04-21T16:38:18.007036Z",
          "shell.execute_reply.started": "2022-04-21T16:38:17.959761Z",
          "shell.execute_reply": "2022-04-21T16:38:18.005911Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "4uKqMncSVfgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to calculate WoE of cat features\n",
        "\n",
        "def woe_categorical(df, cat_feature, good_bad_df):\n",
        "    df = pd.concat([df[cat_feature], good_bad_df], axis=1)\n",
        "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
        "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
        "    df = df.iloc[:, [0, 1, 3]]\n",
        "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
        "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
        "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
        "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
        "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
        "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
        "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
        "    df = df.sort_values(['WoE'])\n",
        "    df = df.reset_index(drop = True)\n",
        "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
        "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
        "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
        "    df['IV'] = df['IV'].sum()\n",
        "    return df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:38:25.778073Z",
          "iopub.execute_input": "2022-04-21T16:38:25.778423Z",
          "iopub.status.idle": "2022-04-21T16:38:25.791979Z",
          "shell.execute_reply.started": "2022-04-21T16:38:25.778388Z",
          "shell.execute_reply": "2022-04-21T16:38:25.790835Z"
        },
        "trusted": true,
        "id": "xFDvGSNaVfgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot WoE\n",
        "import numpy as np\n",
        "\n",
        "def plot_by_woe(df_WoE, rotation_of_x_axis_labels = 0):\n",
        "    x = np.array(df_WoE.iloc[:, 0].apply(str))\n",
        "    y = df_WoE['WoE']\n",
        "    plt.figure(figsize=(18, 12))\n",
        "    plt.plot(x, y, marker = 'o', color = 'hotpink', linestyle = 'dashed', linewidth = 3, markersize = 18, markeredgecolor = 'cyan', markerfacecolor = 'black')\n",
        "    plt.xlabel(df_WoE.columns[0])\n",
        "    plt.ylabel('Weight of Evidence')\n",
        "    plt.title(str('Weight of Evidence by ' + df_WoE.columns[0]))\n",
        "    plt.xticks(rotation = rotation_of_x_axis_labels)\n",
        "    plt.xticks(fontsize=14)\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:54:34.794649Z",
          "iopub.execute_input": "2022-04-21T16:54:34.79498Z",
          "iopub.status.idle": "2022-04-21T16:54:34.805953Z",
          "shell.execute_reply.started": "2022-04-21T16:54:34.79495Z",
          "shell.execute_reply": "2022-04-21T16:54:34.804649Z"
        },
        "trusted": true,
        "id": "EtRxS8bKVfgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seperating data into target and features\n",
        "X= preprocess_data.drop(columns='bad_loan', axis=1)\n",
        "y=preprocess_data['bad_loan']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:39:10.525278Z",
          "iopub.execute_input": "2022-04-21T16:39:10.525936Z",
          "iopub.status.idle": "2022-04-21T16:39:10.568114Z",
          "shell.execute_reply.started": "2022-04-21T16:39:10.525898Z",
          "shell.execute_reply": "2022-04-21T16:39:10.567316Z"
        },
        "_kg_hide-input": false,
        "trusted": true,
        "id": "5XHS96NgVfgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing Categorical Variables by Plotting WoE"
      ],
      "metadata": {
        "id": "I6-BnUG2VfgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Analyzing Grade variable**"
      ],
      "metadata": {
        "id": "NJVsgkCSVfgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_grade = woe_categorical(X, 'grade', y)\n",
        "plot_by_woe(df_grade)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:54:40.443568Z",
          "iopub.execute_input": "2022-04-21T16:54:40.444728Z",
          "iopub.status.idle": "2022-04-21T16:54:40.72508Z",
          "shell.execute_reply.started": "2022-04-21T16:54:40.444625Z",
          "shell.execute_reply": "2022-04-21T16:54:40.72403Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "EDq9SAyqVfgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see from the above graph that the grades have significantly different woe as we grade changes. We will therefore keep each grade as a feature."
      ],
      "metadata": {
        "id": "ryb8jp2DVfgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Analyzing Home Ownership variable**"
      ],
      "metadata": {
        "id": "Of5rs-LIVfgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_home = woe_categorical(X, 'home_ownership', y)\n",
        "plot_by_woe(df_home)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:53:57.297695Z",
          "iopub.execute_input": "2022-04-21T16:53:57.298179Z",
          "iopub.status.idle": "2022-04-21T16:53:57.581562Z",
          "shell.execute_reply.started": "2022-04-21T16:53:57.298145Z",
          "shell.execute_reply": "2022-04-21T16:53:57.580677Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "60_TdRggVfgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OTHER, NONE and ANY have very few observations and should be combined with the category with high risk of default that is RENT"
      ],
      "metadata": {
        "id": "LE2vTYNpVfgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Analyzing Verification status variable**"
      ],
      "metadata": {
        "id": "2iPrHIkVVfgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "veri_df = woe_categorical(X, 'verification_status', y)\n",
        "plot_by_woe(veri_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:32:55.874731Z",
          "iopub.execute_input": "2022-04-21T07:32:55.875037Z",
          "iopub.status.idle": "2022-04-21T07:32:56.151411Z",
          "shell.execute_reply.started": "2022-04-21T07:32:55.875007Z",
          "shell.execute_reply": "2022-04-21T07:32:56.150756Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "n9HJZCuWVfgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This variable has different WoE values and can be used as seperate variables"
      ],
      "metadata": {
        "id": "YtHIjMHsVfgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Analyzing Purpose variable**"
      ],
      "metadata": {
        "id": "qsX-fFQAVfgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pur_df = woe_categorical(X, 'purpose', y)\n",
        "plot_by_woe(pur_df, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:33:06.461529Z",
          "iopub.execute_input": "2022-04-21T07:33:06.462189Z",
          "iopub.status.idle": "2022-04-21T07:33:06.840536Z",
          "shell.execute_reply.started": "2022-04-21T07:33:06.462147Z",
          "shell.execute_reply": "2022-04-21T07:33:06.839647Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "srSOwH9IVfgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following categories wil be combined together:\n",
        "\n",
        "educational, renewable_energy, moving\n",
        "other,house, medical\n",
        "weeding, vacation\n",
        "debt_consolidation\n",
        "home_improvement, major purchase\n",
        "car, credit_card"
      ],
      "metadata": {
        "id": "iG3btlPSVfgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Analyzing address-state variable**"
      ],
      "metadata": {
        "id": "0pEMXpLUVfgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "addr_df = woe_categorical(X, 'addr_state', y)\n",
        "plot_by_woe(addr_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:54:52.197803Z",
          "iopub.execute_input": "2022-04-21T16:54:52.198127Z",
          "iopub.status.idle": "2022-04-21T16:54:52.826579Z",
          "shell.execute_reply.started": "2022-04-21T16:54:52.198091Z",
          "shell.execute_reply": "2022-04-21T16:54:52.825242Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "ZOqpyPKvVfgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The states NE, IA, ME and ID have low observations and this may be the reason for their extreme woe. We will plot the graph again excluding these categories and see if there is any change."
      ],
      "metadata": {
        "id": "DGGLuglhVfgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 =addr_df.iloc[2:44, :]\n",
        "data2 =addr_df.iloc[45:49, :]\n",
        "low_data_woe = pd.concat([data1, data2], axis=0)\n",
        "plot_by_woe(low_data_woe)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:34:37.339744Z",
          "iopub.execute_input": "2022-04-21T07:34:37.340042Z",
          "iopub.status.idle": "2022-04-21T07:34:37.346935Z",
          "shell.execute_reply.started": "2022-04-21T07:34:37.340002Z",
          "shell.execute_reply": "2022-04-21T07:34:37.345903Z"
        },
        "trusted": true,
        "id": "nwAcL3LdVfgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In deciding which categories to combine we use both WOE and the number of observations in our analysis. Categories with similar WoE but significantly different observations will not be combined together, because the number of observations can influence the WoE values. Also, categories with both similar WoE and observations greater than 5% can be combined together to form a new category. This process will be used for the rest of analysis.The categories to be combined as follows:\n",
        "\n",
        "- NE, IA, NV, HI, FL, AL\n",
        "- NY\n",
        "- LA, NM, OK, NC, MO, MD, NJ, VA\n",
        "- CA\n",
        "- AZ, MI, UT, TN, AR, PA\n",
        "- RI, OH, KY, DE, MN, SD, MA, IN\n",
        "- GA, WA\n",
        "- WI, OR\n",
        "- TX\n",
        "- IL, CT,MT\n",
        "- CO, SC\n",
        "- KS, VT, AK, MS\n",
        "- NH, WV, WY, DC\n",
        "\n",
        "In total we will have to create 13 categories for the addr_variable. We will create these variables later. Let us move on to analyze the rest of the features."
      ],
      "metadata": {
        "id": "m1BGOdGUVfgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Analyzing initial list status variable**"
      ],
      "metadata": {
        "id": "7X1kaQ4wVfgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_list_df = woe_categorical( X, 'initial_list_status', y)\n",
        "plot_by_woe(init_list_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:47:05.759055Z",
          "iopub.execute_input": "2022-04-21T16:47:05.759763Z",
          "iopub.status.idle": "2022-04-21T16:47:06.095162Z",
          "shell.execute_reply.started": "2022-04-21T16:47:05.759707Z",
          "shell.execute_reply": "2022-04-21T16:47:06.094231Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "d0kZ8p8bVfgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This variable has significantly different WoE values and categories should be kept as seperate variables"
      ],
      "metadata": {
        "id": "HDZwSnKNVfgF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing Continous Variables by Plotting WoE"
      ],
      "metadata": {
        "id": "b7j1dT42VfgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to calculate WoE for continous variables\n",
        "def woe_continous(df, cat_feature, good_bad_df):\n",
        "    df = pd.concat([df[cat_feature], good_bad_df], axis=1)\n",
        "    df = pd.concat([df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].count(),\n",
        "                    df.groupby(df.columns.values[0], as_index = False)[df.columns.values[1]].mean()], axis = 1)\n",
        "    df = df.iloc[:, [0, 1, 3]]\n",
        "    df.columns = [df.columns.values[0], 'n_obs', 'prop_good']\n",
        "    df['prop_n_obs'] = df['n_obs'] / df['n_obs'].sum()\n",
        "    df['n_good'] = df['prop_good'] * df['n_obs']\n",
        "    df['n_bad'] = (1 - df['prop_good']) * df['n_obs']\n",
        "    df['prop_n_good'] = df['n_good'] / df['n_good'].sum()\n",
        "    df['prop_n_bad'] = df['n_bad'] / df['n_bad'].sum()\n",
        "    df['WoE'] = np.log(df['prop_n_good'] / df['prop_n_bad'])\n",
        "    df['diff_prop_good'] = df['prop_good'].diff().abs()\n",
        "    df['diff_WoE'] = df['WoE'].diff().abs()\n",
        "    df['IV'] = (df['prop_n_good'] - df['prop_n_bad']) * df['WoE']\n",
        "    df['IV'] = df['IV'].sum()\n",
        "    return df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:47:20.881236Z",
          "iopub.execute_input": "2022-04-21T16:47:20.882205Z",
          "iopub.status.idle": "2022-04-21T16:47:20.895693Z",
          "shell.execute_reply.started": "2022-04-21T16:47:20.882153Z",
          "shell.execute_reply": "2022-04-21T16:47:20.894693Z"
        },
        "trusted": true,
        "id": "buHz0SopVfgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Analyzing term variable**"
      ],
      "metadata": {
        "id": "-lFbiJh0VfgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_by_woe(woe_continous(X,'term', y ))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T16:47:23.817444Z",
          "iopub.execute_input": "2022-04-21T16:47:23.8184Z",
          "iopub.status.idle": "2022-04-21T16:47:24.124952Z",
          "shell.execute_reply.started": "2022-04-21T16:47:23.818355Z",
          "shell.execute_reply": "2022-04-21T16:47:24.123972Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Nc_d2m74VfgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Analyzing months since issued variable**"
      ],
      "metadata": {
        "id": "suvN3KZDVfgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['mths_since_issue_d'].unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:37:10.114465Z",
          "iopub.execute_input": "2022-04-21T07:37:10.114784Z",
          "iopub.status.idle": "2022-04-21T07:37:10.12382Z",
          "shell.execute_reply.started": "2022-04-21T07:37:10.114751Z",
          "shell.execute_reply": "2022-04-21T07:37:10.123078Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "h_9rELVsVfgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine class by creating  a new var\n",
        "\n",
        "X['mths_since_issue_d_factor'] = pd.cut(X['mths_since_issue_d'], 10)\n",
        "mths_since_iss_df = woe_continous(X, 'mths_since_issue_d_factor', y)\n",
        "plot_by_woe(mths_since_iss_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:37:32.861068Z",
          "iopub.execute_input": "2022-04-21T07:37:32.861363Z",
          "iopub.status.idle": "2022-04-21T07:37:33.179367Z",
          "shell.execute_reply.started": "2022-04-21T07:37:32.861331Z",
          "shell.execute_reply": "2022-04-21T07:37:33.178516Z"
        },
        "trusted": true,
        "id": "W77K1r04VfgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The follwing categories will be created based on their WoE and number of observations\n",
        "\n",
        "- (67.97, 70.8)\n",
        "- (70.8, 73.6)\n",
        "- (73.6- 76.4)\n",
        "- (76.4.- 79.2)\n",
        "- (79.2-82)\n",
        "- (82-84)\n",
        "- (84-90.4)\n",
        "- (90.4-96)"
      ],
      "metadata": {
        "id": "7PukJuIrVfgG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Analyzing interest rate variable**"
      ],
      "metadata": {
        "id": "5hHw_WvJVfgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['int_rate_factor'] = pd.cut(X['int_rate'], 10)\n",
        "int_rate_df = woe_continous(X, 'int_rate_factor',y)\n",
        "plot_by_woe(int_rate_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:39:27.714122Z",
          "iopub.execute_input": "2022-04-21T07:39:27.714476Z",
          "iopub.status.idle": "2022-04-21T07:39:28.047452Z",
          "shell.execute_reply.started": "2022-04-21T07:39:27.714439Z",
          "shell.execute_reply": "2022-04-21T07:39:28.046386Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "mbOir3u5VfgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph above only the last two categories will be combined.\n",
        "\n",
        "(22.048, 26)"
      ],
      "metadata": {
        "id": "W8T-KKxbVfgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Analyzing total_rec_int variable**"
      ],
      "metadata": {
        "id": "rbPqF5kEVfgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['total_rec_int_factor'] = pd.cut(X['total_rec_int'], 20)\n",
        "rec_int_df = woe_continous(X, 'total_rec_int_factor', y)\n",
        "plot_by_woe(rec_int_df, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:40:03.277831Z",
          "iopub.execute_input": "2022-04-21T07:40:03.27813Z",
          "iopub.status.idle": "2022-04-21T07:40:03.717162Z",
          "shell.execute_reply.started": "2022-04-21T07:40:03.278097Z",
          "shell.execute_reply": "2022-04-21T07:40:03.71614Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "L90jTg79VfgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Analyzing toal revolving_high_limit variable**"
      ],
      "metadata": {
        "id": "eBQf0V1sVfgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['total_rev_hi_lim_factor'] = pd.cut(X['total_rev_hi_lim'], 100)\n",
        "revol_hi_df = woe_continous(X, 'total_rev_hi_lim_factor', y)\n",
        "#plot_by_woe(revol_hi_df, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:41:24.87354Z",
          "iopub.execute_input": "2022-04-21T07:41:24.873877Z",
          "iopub.status.idle": "2022-04-21T07:41:25.389488Z",
          "shell.execute_reply.started": "2022-04-21T07:41:24.873837Z",
          "shell.execute_reply": "2022-04-21T07:41:25.388591Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "m397lt6PVfgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analyzing below 100000\n",
        "X_train_prepr_temp = X[X['total_rev_hi_lim'] <= 100000].copy()\n",
        "# fine-classing\n",
        "X_train_prepr_temp['total_rev_hi_lim_factor'] = pd.cut(X_train_prepr_temp['total_rev_hi_lim'],10)\n",
        "# select only the relevant index in the target col\n",
        "df_temp = woe_continous(X_train_prepr_temp, 'total_rev_hi_lim_factor', y[X_train_prepr_temp.index])\n",
        "plot_by_woe(df_temp, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:43:01.512891Z",
          "iopub.execute_input": "2022-04-21T07:43:01.513197Z",
          "iopub.status.idle": "2022-04-21T07:43:02.022439Z",
          "shell.execute_reply.started": "2022-04-21T07:43:01.513169Z",
          "shell.execute_reply": "2022-04-21T07:43:02.021546Z"
        },
        "trusted": true,
        "id": "p1jOIvqSVfgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Analyzing total_payment variable**"
      ],
      "metadata": {
        "id": "PHW5CEw5VfgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['total_pymnt_factor'] = pd.cut(X['total_pymnt'], 10)\n",
        "total_pym_df = woe_continous(X, 'total_pymnt_factor', y)\n",
        "plot_by_woe(total_pym_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:43:48.201049Z",
          "iopub.execute_input": "2022-04-21T07:43:48.201631Z",
          "iopub.status.idle": "2022-04-21T07:43:48.519014Z",
          "shell.execute_reply.started": "2022-04-21T07:43:48.201591Z",
          "shell.execute_reply": "2022-04-21T07:43:48.518042Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "Vto8swTgVfgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Analyzing dti variable**\n",
        "\n",
        "\"dti\" is a ratio calculated using the borrowers total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrowers self-reported monthly income."
      ],
      "metadata": {
        "id": "-MbUWkoLVfgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['dti_factor'] = pd.cut(X['dti'], 10)\n",
        "dti_df = woe_continous(X, 'dti_factor', y)\n",
        "plot_by_woe(dti_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:44:12.29456Z",
          "iopub.execute_input": "2022-04-21T07:44:12.294859Z",
          "iopub.status.idle": "2022-04-21T07:44:12.641134Z",
          "shell.execute_reply.started": "2022-04-21T07:44:12.294827Z",
          "shell.execute_reply": "2022-04-21T07:44:12.64011Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "jfxBANbJVfgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following categories will be combined:\n",
        "\n",
        "(27.993, 31.992), (31.992, 35.991), (35.991, 39.99)"
      ],
      "metadata": {
        "id": "AcIctQXJVfgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Analyzing annual_income variable**"
      ],
      "metadata": {
        "id": "-mfgf18jVfgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['annual_inc_factor'] = pd.cut(X['annual_inc'], 50)\n",
        "ann_inc_df = woe_continous(X, 'annual_inc_factor', y)\n",
        "plot_by_woe(ann_inc_df, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:44:53.923342Z",
          "iopub.execute_input": "2022-04-21T07:44:53.923984Z",
          "iopub.status.idle": "2022-04-21T07:44:54.342517Z",
          "shell.execute_reply.started": "2022-04-21T07:44:53.923943Z",
          "shell.execute_reply": "2022-04-21T07:44:54.341537Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "mOBZ60DeVfgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will seperate this variable into people with higher and lower incomes. From the WoE table, we observe, when annual income increases, the the number of observations decreases. This is because only a few people earn high income. We will use a new variable for people with income above 150000 dollars. And also, analyze individuals with income below 150000 dollars."
      ],
      "metadata": {
        "id": "FE1UbxoLVfgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing income  below 150000\n",
        "X_train_prepr_temp = X[X['annual_inc'] <= 150000].copy()\n",
        "# fine-classing\n",
        "X_train_prepr_temp['annual_inc_factor'] = pd.cut(X_train_prepr_temp['annual_inc'], 10)\n",
        "# select only the relevant index in the target col\n",
        "df_temp = woe_continous(X_train_prepr_temp, 'annual_inc_factor', y[X_train_prepr_temp.index])\n",
        "plot_by_woe(df_temp, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:45:45.00058Z",
          "iopub.execute_input": "2022-04-21T07:45:45.000864Z",
          "iopub.status.idle": "2022-04-21T07:45:45.481149Z",
          "shell.execute_reply.started": "2022-04-21T07:45:45.000835Z",
          "shell.execute_reply": "2022-04-21T07:45:45.480154Z"
        },
        "trusted": true,
        "id": "I6J5GfCcVfgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph, we will combine the follwing categories based on WoE and number of observations as follows:\n",
        "- (<=32000),\n",
        "- (>32000 <= 50000),\n",
        "- (>50000 <= 60000),\n",
        "- (>60000 <=75000),\n",
        "- (>75000 <=90000),\n",
        "- (>90000 <=120000),\n",
        "- (>120000 <=135000),\n",
        "- (>135000 <=150000),\n",
        "- (>150000)"
      ],
      "metadata": {
        "id": "LFTupcX6VfgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Analyzing inq_last_6mths variable**\n",
        "\n",
        "inq_last_6mths denote the number of inquiries in last 6 months"
      ],
      "metadata": {
        "id": "AVR-EjMYVfgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['inq_last_6mths_factor'] = pd.cut(X['inq_last_6mths'], 7)\n",
        "inq_fact_df = woe_continous(X, 'inq_last_6mths_factor', y)\n",
        "plot_by_woe(inq_fact_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:46:26.034957Z",
          "iopub.execute_input": "2022-04-21T07:46:26.035729Z",
          "iopub.status.idle": "2022-04-21T07:46:26.331803Z",
          "shell.execute_reply.started": "2022-04-21T07:46:26.03568Z",
          "shell.execute_reply": "2022-04-21T07:46:26.331035Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "fsDcDsswVfgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The follwing categories will be created\n",
        "\n",
        "- <1 months,\n",
        "- 1-2,\n",
        "- 2-4,\n",
        "- 4-7"
      ],
      "metadata": {
        "id": "h7mrkeq1VfgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Analyzing total current balance variable**"
      ],
      "metadata": {
        "id": "eC7lBjmmVfgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['tot_cur_bal_factor'] = pd.cut(X['tot_cur_bal'], 20)\n",
        "curr_bal_df = woe_continous(X, 'tot_cur_bal_factor', y)\n",
        "plot_by_woe(curr_bal_df, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:47:51.4529Z",
          "iopub.execute_input": "2022-04-21T07:47:51.45362Z",
          "iopub.status.idle": "2022-04-21T07:47:51.789797Z",
          "shell.execute_reply.started": "2022-04-21T07:47:51.453585Z",
          "shell.execute_reply": "2022-04-21T07:47:51.789155Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "DyFLO99VVfgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing current balance  below 400000\n",
        "X_train_prepr_temp = X[X['tot_cur_bal'] <= 400000].copy()\n",
        "# fine-classing\n",
        "X_train_prepr_temp['tot_cur_bal_factor'] = pd.cut(X_train_prepr_temp['tot_cur_bal'], 10)\n",
        "# select only the relevant index in the target column\n",
        "df_temp = woe_continous(X_train_prepr_temp, 'tot_cur_bal_factor', y[X_train_prepr_temp.index])\n",
        "plot_by_woe(df_temp, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:48:20.012863Z",
          "iopub.execute_input": "2022-04-21T07:48:20.013712Z",
          "iopub.status.idle": "2022-04-21T07:48:20.472573Z",
          "shell.execute_reply.started": "2022-04-21T07:48:20.013671Z",
          "shell.execute_reply": "2022-04-21T07:48:20.471422Z"
        },
        "trusted": true,
        "id": "efJCUP3cVfgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the following variables will be created:\n",
        "- <40000,\n",
        "- 40000-80000,\n",
        "- 80000-120000,\n",
        "- 120000-160000,\n",
        "- 160000-200000,\n",
        "- 200000-240000,\n",
        "- 240000-320000,\n",
        "- 320000-400000"
      ],
      "metadata": {
        "id": "SAPEg2vJVfgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Analyzing months since credit pulled variable**"
      ],
      "metadata": {
        "id": "ZVi0qi4tVfgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['mths_since_last_credit_pull_d_factor'] = pd.cut(X['mths_since_last_credit_pull_d'], 10)\n",
        "mths_cr_pull_df = woe_continous(X, 'mths_since_last_credit_pull_d_factor', y)\n",
        "plot_by_woe(mths_cr_pull_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:49:18.572747Z",
          "iopub.execute_input": "2022-04-21T07:49:18.573089Z",
          "iopub.status.idle": "2022-04-21T07:49:18.900747Z",
          "shell.execute_reply.started": "2022-04-21T07:49:18.573057Z",
          "shell.execute_reply": "2022-04-21T07:49:18.899711Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "P4Kq3V-0VfgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing mths_since_credit_pull  below 60\n",
        "X_train_prepr_temp = X[X['mths_since_last_credit_pull_d'] <= 60].copy()\n",
        "# fine-classing\n",
        "X_train_prepr_temp['mths_since_last_credit_pull_d'] = pd.cut(X_train_prepr_temp['mths_since_last_credit_pull_d'], 5)\n",
        "# select only the relevant index in the target column\n",
        "df_temp = woe_continous(X_train_prepr_temp, 'mths_since_last_credit_pull_d', y[X_train_prepr_temp.index])\n",
        "plot_by_woe(df_temp)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:49:57.615776Z",
          "iopub.execute_input": "2022-04-21T07:49:57.616065Z",
          "iopub.status.idle": "2022-04-21T07:49:58.009209Z",
          "shell.execute_reply.started": "2022-04-21T07:49:57.616036Z",
          "shell.execute_reply": "2022-04-21T07:49:58.008141Z"
        },
        "trusted": true,
        "id": "H9QzQLLcVfgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following categories will be grouped together:\n",
        "- 54-65,\n",
        "- 65-76,\n",
        "- greater than 76"
      ],
      "metadata": {
        "id": "-cuvEKg4VfgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Analyzing out_prncp_factor variable**\n",
        "\n",
        "\"out_prncp_factor\" denotes remaining outstanding principal for total amount funded"
      ],
      "metadata": {
        "id": "ncGaJtPkVfgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['out_prncp_factor'] = pd.cut(X['out_prncp'], 10)\n",
        "out_df = woe_continous(X, 'out_prncp_factor', y)\n",
        "plot_by_woe(out_df, 90)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:50:36.874573Z",
          "iopub.execute_input": "2022-04-21T07:50:36.874879Z",
          "iopub.status.idle": "2022-04-21T07:50:37.232176Z",
          "shell.execute_reply.started": "2022-04-21T07:50:36.874848Z",
          "shell.execute_reply": "2022-04-21T07:50:37.231264Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "m1ebm4YoVfgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Analyzing months_since_issue_date variable**"
      ],
      "metadata": {
        "id": "Ezz0a-quVfgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X['mths_since_issue_d'] = pd.cut(X['mths_since_issue_d'], 10)\n",
        "iss_df = woe_continous(X, 'mths_since_issue_d', y)\n",
        "plot_by_woe(iss_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-04-21T07:51:08.733145Z",
          "iopub.execute_input": "2022-04-21T07:51:08.734221Z",
          "iopub.status.idle": "2022-04-21T07:51:09.015084Z",
          "shell.execute_reply.started": "2022-04-21T07:51:08.734178Z",
          "shell.execute_reply": "2022-04-21T07:51:09.014242Z"
        },
        "_kg_hide-input": true,
        "trusted": true,
        "id": "C38SQPMCVfgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating New Features Based on WoE"
      ],
      "metadata": {
        "id": "I5lk-AicVfgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grade\n",
        "\n",
        "new_df = preprocess_data.loc[:, 'grade:A':'grade:G']\n",
        "\n",
        "# home_ownership\n",
        "\n",
        "new_df['home_ownership:OWN'] = preprocess_data.loc[:, 'home_ownership:OWN']\n",
        "new_df['home_ownership:OTHER_NONE_RENT_ANY'] = sum([preprocess_data['home_ownership:OTHER'],\n",
        "                                                    preprocess_data['home_ownership:NONE'],\n",
        "                                                    preprocess_data['home_ownership:RENT'],\n",
        "                                                    preprocess_data['home_ownership:ANY']])\n",
        "new_df['home_ownership:MORTGAGE'] = preprocess_data.loc[:, 'home_ownership:MORTGAGE']\n",
        "\n",
        "#verification status\n",
        "new_df['verification_status:NOT_VERIFIED'] = preprocess_data.loc[:, 'verification_status:Not Verified']\n",
        "new_df['verification_status:SOURCE_VERIFIED'] = preprocess_data.loc[:, 'verification_status:Source Verified']\n",
        "new_df['verification_status:VERIFIED'] = preprocess_data.loc[:, 'verification_status:Verified']\n",
        "\n",
        "# purpose of loan\n",
        "new_df['purpose:SMALL_BUSINESS_EDUCATIONAL_RENEWABLE_ENERGY_MOVING'] = sum([preprocess_data['purpose:small_business'],  preprocess_data['purpose:renewable_energy'], preprocess_data['purpose:moving']])\n",
        "new_df['purpose:OTHER_HOUSE_MEDICAL'] =sum([preprocess_data['purpose:other'], preprocess_data['purpose:house'], preprocess_data['purpose:medical']])\n",
        "new_df ['purpose:WEDDING_VACATION'] = sum([preprocess_data['purpose:wedding'], preprocess_data['purpose:vacation']])\n",
        "new_df ['purpose:HOME_IMPROVEMENT_MAJOR_PURCHASE'] = sum([preprocess_data['purpose:home_improvement'], preprocess_data['purpose:major_purchase']])\n",
        "new_df ['purpose:CAR_CREDIT_CARD'] = sum([preprocess_data['purpose:car'], preprocess_data['purpose:credit_card']])\n",
        "\n",
        "\n",
        "# addr state\n",
        "new_df['addr_state:NE_IA_NV_HI_FL_AL'] =sum([preprocess_data['addr_state:IA'],preprocess_data['addr_state:NV'],\n",
        "                                             preprocess_data['addr_state:HI'],preprocess_data['addr_state:FL'],\n",
        "                                             preprocess_data['addr_state:AL']])\n",
        "new_df['addr_state:NY'] = preprocess_data.loc[:, 'addr_state:NY']\n",
        "new_df['addr_state:LA_NM_OK_NC_MO_MD_NJ_VA'] = sum([preprocess_data['addr_state:LA'],preprocess_data['addr_state:NM'],preprocess_data['addr_state:OK'],\n",
        "                                                    preprocess_data['addr_state:NC'],preprocess_data['addr_state:MO'],preprocess_data['addr_state:MD'], preprocess_data['addr_state:NJ'],\n",
        "                                                    preprocess_data['addr_state:VA']])\n",
        "new_df['addr_state:CA'] = preprocess_data.loc[:,'addr_state:CA']\n",
        "new_df['addr_state:AZ_MI_UT_TN_AR_PA'] =sum([preprocess_data['addr_state:AZ'],preprocess_data['addr_state:MI'],preprocess_data['addr_state:UT'],\n",
        "preprocess_data['addr_state:TN'],preprocess_data['addr_state:AR'],preprocess_data['addr_state:PA']])\n",
        "\n",
        "new_df['addr_state:RI_OH_KY_DE_MN_SD_MA_IN'] =sum([preprocess_data['addr_state:RI'],preprocess_data['addr_state:OH'],preprocess_data['addr_state:KY'],\n",
        "                                                   preprocess_data['addr_state:DE'],preprocess_data['addr_state:MN'],preprocess_data['addr_state:SD'],preprocess_data['addr_state:MA'],\n",
        "                                                   preprocess_data['addr_state:IN']])\n",
        "\n",
        "new_df['addr_state:GA_WA'] = sum([preprocess_data['addr_state:GA'], preprocess_data['addr_state:WA']])\n",
        "new_df['addr_state:WI_OR'] = sum([preprocess_data['addr_state:WI'], preprocess_data['addr_state:OR']])\n",
        "new_df['addr_state:TX'] = preprocess_data.loc[:,'addr_state:TX']\n",
        "new_df['addr_state:IL_CT_MT'] =sum([preprocess_data['addr_state:IL'],preprocess_data['addr_state:CT'],preprocess_data['addr_state:MT']])\n",
        "new_df['addr_state:CO_SC'] = sum([preprocess_data['addr_state:CO'], preprocess_data['addr_state:SC']])\n",
        "new_df['addr_state:KS_VT_AK_NS'] =sum([preprocess_data['addr_state:KS'],preprocess_data['addr_state:VT'],preprocess_data['addr_state:AK'],\n",
        "                                           preprocess_data['addr_state:MS']])\n",
        "new_df['addr_state:NH_WV_WY_DC'] =sum([preprocess_data['addr_state:NH'],preprocess_data['addr_state:WV'],preprocess_data['addr_state:WY'],\n",
        "                                           preprocess_data['addr_state:DC']])\n",
        "#initial_list_status\n",
        "new_df['initial_list_status:F'] = preprocess_data.loc[:, 'initial_list_status:f']\n",
        "new_df['initial_list_status:W'] = preprocess_data.loc[:, 'initial_list_status:w']\n",
        "\n",
        "# term\n",
        "new_df['term:36'] = np.where((preprocess_data['term'] == 36), 1, 0)\n",
        "new_df['term:60'] = np.where((preprocess_data['term']==60), 1,0)\n",
        "\n",
        "#total_rec_int\n",
        "new_df['total_rec_int:<1000'] = np.where((preprocess_data['total_rec_int']<=1000), 1,0)\n",
        "new_df['total_rec_int:1000-2000'] = np.where((preprocess_data['total_rec_int']>1000) &(preprocess_data['total_rec_int']<=2000), 1,0)\n",
        "new_df['total_rec_int:2000-9000'] = np.where((preprocess_data['total_rec_int']>2000) &(preprocess_data['total_rec_int']<=9000), 1,0)\n",
        "new_df['total_rec_int:>9000'] = np.where((preprocess_data['total_rec_int']>9000), 1,0)\n",
        "\n",
        "\n",
        "#total_revol_hi_lim\n",
        "new_df['total_rev_hi_lim:<10000'] =np.where((preprocess_data['total_rev_hi_lim']<=10000),1,0)\n",
        "new_df['total_rev_hi_lim:10000-20000'] =np.where((preprocess_data['total_rev_hi_lim']>10000)&(preprocess_data['total_rev_hi_lim']<=20000),1,0)\n",
        "new_df['total_rev_hi_lim:20000-40000'] =np.where((preprocess_data['total_rev_hi_lim']>20000)&(preprocess_data['total_rev_hi_lim']<=40000),1,0)\n",
        "new_df['total_rev_hi_lim:40000-60000'] =np.where((preprocess_data['total_rev_hi_lim']>40000)&(preprocess_data['total_rev_hi_lim']<=60000),1,0)\n",
        "new_df['total_rev_hi_lim:60000-80000'] =np.where((preprocess_data['total_rev_hi_lim']>60000)&(preprocess_data['total_rev_hi_lim']<=80000),1,0)\n",
        "new_df['total_rev_hi_lim:80000-100000'] =np.where((preprocess_data['total_rev_hi_lim']>80000)&(preprocess_data['total_rev_hi_lim']<=100000),1,0)\n",
        "new_df['total_rev_hi_lim:<100000'] =np.where((preprocess_data['total_rev_hi_lim']>100000),1,0)\n",
        "\n",
        "\n",
        "#total_pymnt\n",
        "new_df['total_pymnt:<5000'] = np.where((preprocess_data['total_pymnt']<=5000), 1,0)\n",
        "new_df['total_pymnt:5000-11000'] = np.where((preprocess_data['total_pymnt']>5000)&(preprocess_data['total_pymnt']<=11000),1,0)\n",
        "new_df['total_pymnt:11000-16000'] = np.where((preprocess_data['total_pymnt']>11000)&(preprocess_data['total_pymnt']<=16000),1,0)\n",
        "new_df['total_pymnt:16000-22000'] = np.where((preprocess_data['total_pymnt']>16000)&(preprocess_data['total_pymnt']<=22000),1,0)\n",
        "new_df['total_pymnt:>22000'] = np.where((preprocess_data['total_pymnt']<=5000), 1,0)\n",
        "#int_Rate\n",
        "\n",
        "new_df['int_rate:<7.484'] = np.where((preprocess_data['int_rate'] <= 7.484), 1, 0)\n",
        "new_df['int_rate:7.484-9.548'] = np.where((preprocess_data['int_rate'] > 7.484) & (preprocess_data['int_rate'] <= 9.548), 1, 0)\n",
        "new_df['int_rate:9.548-11.612'] = np.where((preprocess_data['int_rate'] > 9.548) & (preprocess_data['int_rate'] <= 11.612), 1, 0)\n",
        "new_df['int_rate:11.612-13.676'] = np.where((preprocess_data['int_rate'] > 11.612) & (preprocess_data['int_rate'] <= 13.676), 1, 0)\n",
        "new_df['int_rate:13.676-15.74'] = np.where((preprocess_data['int_rate'] > 13.676) & (preprocess_data['int_rate'] <= 15.74), 1, 0)\n",
        "new_df['int_rate:15.74-17.804'] = np.where((preprocess_data['int_rate'] > 15.74) & (preprocess_data['int_rate'] <= 17.804), 1, 0)\n",
        "new_df['int_rate:17.804-19.868'] = np.where((preprocess_data['int_rate'] > 17.804) & (preprocess_data['int_rate'] <= 19.868), 1, 0)\n",
        "new_df['int_rate:7.19.868-21.932'] = np.where((preprocess_data['int_rate'] > 19.868) & (preprocess_data['int_rate'] <= 21.932), 1, 0)\n",
        "new_df['int_rate:21.932-26.06'] = np.where((preprocess_data['int_rate'] > 21.932) & (preprocess_data['int_rate'] <= 26.06), 1, 0)\n",
        "\n",
        "\n",
        "#dti\n",
        "new_df['dti:<4'] = np.where((preprocess_data['dti'] <=4), 1, 0)\n",
        "new_df['dti:4-8'] = np.where((preprocess_data['dti'] > 4) & (preprocess_data['dti'] <= 8), 1, 0)\n",
        "new_df['dti:8-12'] = np.where((preprocess_data['dti'] > 8) & (preprocess_data['dti'] <= 12), 1, 0)\n",
        "new_df['dti:12-16'] = np.where((preprocess_data['dti'] > 12) & (preprocess_data['dti'] <= 16), 1, 0)\n",
        "new_df['dti:16-20'] = np.where((preprocess_data['dti'] > 16) & (preprocess_data['dti'] <= 20), 1, 0)\n",
        "new_df['dti:20-23'] = np.where((preprocess_data['dti'] > 20) & (preprocess_data['dti'] <= 23), 1, 0)\n",
        "new_df['dti:23-27'] = np.where((preprocess_data['dti'] > 23) & (preprocess_data['dti'] <= 27), 1, 0)\n",
        "new_df['dti:27-40'] = np.where((preprocess_data['dti'] > 27) & (preprocess_data['dti'] <= 40), 1, 0)\n",
        "\n",
        "#annual income\n",
        "new_df['annual_inc:<32000'] = np.where((preprocess_data['annual_inc'] <= 32000), 1, 0)\n",
        "new_df['annual_inc:32000-50000'] = np.where((preprocess_data['annual_inc'] > 32000) & (preprocess_data['annual_inc'] <= 50000),1, 0)\n",
        "new_df['annual_inc:32000-50000'] = np.where((preprocess_data['annual_inc'] > 32000) & (preprocess_data['annual_inc'] <= 50000), 1, 0)\n",
        "new_df['annual_inc:50000-60000'] = np.where((preprocess_data['annual_inc'] > 50000) & (preprocess_data['annual_inc'] <= 60000), 1, 0)\n",
        "new_df['annual_inc:60000-75000'] = np.where((preprocess_data['annual_inc'] > 60000) & (preprocess_data['annual_inc'] <= 75000), 1, 0)\n",
        "new_df['annual_inc:75000-90000'] = np.where((preprocess_data['annual_inc'] > 75000) & (preprocess_data['annual_inc'] <= 90000), 1, 0)\n",
        "new_df['annual_inc:90000-120000'] = np.where((preprocess_data['annual_inc'] > 90000) & (preprocess_data['annual_inc'] <= 120000), 1, 0)\n",
        "new_df['annual_inc:120000-135000'] = np.where((preprocess_data['annual_inc'] > 120000) & (preprocess_data['annual_inc'] <= 135000), 1, 0)\n",
        "new_df['annual_inc:135000-150000'] = np.where((preprocess_data['annual_inc'] > 135000) & (preprocess_data['annual_inc'] <= 150000), 1, 0)\n",
        "new_df['annual_inc:>150000'] = np.where((preprocess_data['annual_inc'] > 150000), 1, 0)\n",
        "\n",
        "#inq_last_6mths\n",
        "new_df['inq_last_6mths:<1'] = np.where((preprocess_data['inq_last_6mths'] <=1), 1, 0)\n",
        "new_df['inq_last_6mths:1-2'] = np.where((preprocess_data['inq_last_6mths'] >1)& (preprocess_data['inq_last_6mths']<=2),  1, 0)\n",
        "new_df['inq_last_6mths:2-4'] = np.where((preprocess_data['inq_last_6mths'] >2)& (preprocess_data['inq_last_6mths']<=4),  1, 0)\n",
        "new_df['inq_last_6mths:4-7'] = np.where((preprocess_data['inq_last_6mths'] >4)& (preprocess_data['inq_last_6mths']<=7),  1, 0)\n",
        "\n",
        "#tot_cur_balance\n",
        "new_df['tot_cur_bal:<40000'] = np.where((preprocess_data['tot_cur_bal'] <= 40000), 1, 0)\n",
        "new_df['tot_cur_bal:40000-80000'] = np.where((preprocess_data['tot_cur_bal'] > 40000) & (preprocess_data['tot_cur_bal'] <= 80000), 1, 0)\n",
        "new_df['tot_cur_bal:80000-120000'] = np.where((preprocess_data['tot_cur_bal'] > 120000) & (preprocess_data['tot_cur_bal'] <= 160000), 1, 0)\n",
        "new_df['tot_cur_bal:120000-160000'] = np.where((preprocess_data['tot_cur_bal'] > 120000) & (preprocess_data['tot_cur_bal'] <= 160000), 1, 0)\n",
        "new_df['tot_cur_bal:160000-200000'] = np.where((preprocess_data['tot_cur_bal'] > 160000) & (preprocess_data['tot_cur_bal'] <= 200000), 1, 0)\n",
        "new_df['tot_cur_bal:200000-240000'] = np.where((preprocess_data['tot_cur_bal'] > 200000) & (preprocess_data['tot_cur_bal'] <= 240000), 1, 0)\n",
        "new_df['tot_cur_bal:240000-320000'] = np.where((preprocess_data['tot_cur_bal'] > 240000) & (preprocess_data['tot_cur_bal'] <= 320000), 1, 0)\n",
        "new_df['tot_cur_bal:320000-400000'] = np.where((preprocess_data['tot_cur_bal'] > 320000) & (preprocess_data['tot_cur_bal'] <= 400000), 1, 0)\n",
        "new_df['tot_cur_bal:>400000'] = np.where((preprocess_data['tot_cur_bal'] > 400000), 1, 0)\n",
        "\n",
        "#mths_since_last_credit_pull_d\n",
        "new_df['mths_since_last_credit_pull_d:<65'] = np.where((preprocess_data['mths_since_last_credit_pull_d']<=65), 1,0)\n",
        "new_df['mths_since_last_credit_pull_d:65-76'] = np.where((preprocess_data['mths_since_last_credit_pull_d']>65)&(preprocess_data['mths_since_last_credit_pull_d']<=76),1,0)\n",
        "new_df['mths_since_last_credit_pull_d:>76'] = np.where((preprocess_data['mths_since_last_credit_pull_d']>76), 1,0)\n",
        "\n",
        "#mths_since_issue_d_factor\n",
        "new_df['mths_since_issue_d_:<70.8'] = np.where((preprocess_data['mths_since_issue_d']<=70.8), 1,0)\n",
        "new_df['mths_since_issue_d_:>70.8-73.6'] = np.where((preprocess_data['mths_since_issue_d'] >70.8) & (preprocess_data['mths_since_issue_d']<=73.6), 1,0)\n",
        "new_df['mths_since_issue_d_:73.6-76.4'] = np.where((preprocess_data['mths_since_issue_d']>70.8) & (preprocess_data['mths_since_issue_d']<=76.4), 1,0)\n",
        "new_df['mths_since_issue_d_:>76.4-79.2'] = np.where((preprocess_data['mths_since_issue_d'] >76.4) & (preprocess_data['mths_since_issue_d']<=79.2), 1,0)\n",
        "new_df['mths_since_issue_d_:>79.2-82'] = np.where((preprocess_data['mths_since_issue_d'] >79.2) & (preprocess_data['mths_since_issue_d']<=82), 1,0)\n",
        "new_df['mths_since_issue_d_>82-84'] = np.where((preprocess_data['mths_since_issue_d'] >82) & (preprocess_data['mths_since_issue_d']<=84), 1,0)\n",
        "new_df['mths_since_issue_d_:>84-90.4'] = np.where((preprocess_data['mths_since_issue_d'] >84) & (preprocess_data['mths_since_issue_d']<=90.4), 1,0)\n",
        "new_df['mths_since_issue_d_:>90.4-96'] = np.where((preprocess_data['mths_since_issue_d'] >90.4) & (preprocess_data['mths_since_issue_d']<=96), 1,0)\n",
        "\n",
        "new_df['out_prncp:<3000'] = np.where((preprocess_data['out_prncp']<=3000), 1,0)\n",
        "new_df['out_prncp:3000-6000'] = np.where((preprocess_data['out_prncp']>3000)&(preprocess_data['out_prncp']<=6000), 1,0)\n",
        "new_df['out_prncp:6000-10000'] = np.where((preprocess_data['out_prncp']>6000)&(preprocess_data['out_prncp']<=10000), 1,0)\n",
        "new_df['out_prncp:10000-12000'] = np.where((preprocess_data['out_prncp']>10000)&(preprocess_data['out_prncp']<=12000), 1,0)\n",
        "new_df['out_prncp:>12000'] = np.where((preprocess_data['out_prncp']>12000), 1,0)\n",
        "\n",
        "new_df['bad_loan'] = preprocess_data.loc[:, 'bad_loan']"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "CQY3cLRdVfgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying first 10 rows of new_df\n",
        "pd.options.display.max_columns = None\n",
        "new_df.head(10)"
      ],
      "metadata": {
        "id": "3omCtGj2VfgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df1 = new_df"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "iDt3P2YAVfgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we must remove 1 dummy variable for each original variable, otherwise we will get into the [dummy variable trap](https://www.geeksforgeeks.org/ml-dummy-variable-trap-in-regression-models/). The dummy variables to be removed are those with the lowest WoE."
      ],
      "metadata": {
        "id": "b-PTCfV7VfgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dummy categories to drop\n",
        "ref_categories = ['home_ownership:OTHER_NONE_RENT_ANY', 'total_rec_int:<1000', 'total_pymnt:<5000','total_rev_hi_lim:<10000', 'grade:G', 'verification_status:VERIFIED', 'purpose:SMALL_BUSINESS_EDUCATIONAL_RENEWABLE_ENERGY_MOVING',\n",
        "                 'addr_state:NE_IA_NV_HI_FL_AL', 'initial_list_status:F', 'term:60', 'mths_since_issue_d_:>90.4-96','int_rate:21.932-26.06', 'dti:27-40',\n",
        "                 'annual_inc:<32000', 'inq_last_6mths:4-7', 'tot_cur_bal:<40000', 'mths_since_last_credit_pull_d:>76', 'out_prncp:>12000']\n",
        "#col dropped\n",
        "new_df.drop(columns=ref_categories, inplace=True, axis=1)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "id": "3wnkTeUQVfgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking for Class Imbalance in the Fully Preprocessed Dataset"
      ],
      "metadata": {
        "id": "zFFjc9FuVfgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check if class labels are balanced\n",
        "\n",
        "from yellowbrick.target import ClassBalance\n",
        "X= new_df.drop(columns='bad_loan', axis=1)\n",
        "y = new_df['bad_loan']\n",
        "visualizer = ClassBalance()\n",
        "visualizer.fit(y)\n",
        "visualizer.show()"
      ],
      "metadata": {
        "id": "H-0b1bboVfgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the chart above, we see the individuals classified as bad borrowers have very few observations. This class imbalance can affect our model while training. To solve this problem, we will oversample the minority class."
      ],
      "metadata": {
        "id": "aoPeaI4TVfgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting into Train and Test"
      ],
      "metadata": {
        "id": "Gkynq20lVfgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#spliting data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "#checking  imbalance for training dataset\n",
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "yQER9qaCVfgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oversampling Minority Class to Resolve Class Imbalance"
      ],
      "metadata": {
        "id": "5LHc1KtAVfgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries for model training\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, precision_recall_curve\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.combine import SMOTETomek"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "vDl017ZcVfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dealing with imbalanced data\n",
        "os = RandomOverSampler()\n",
        "X_train_o, y_train_o = os.fit_resample(X_train, y_train)\n",
        "y_train_series = pd.Series(y_train_o)\n",
        "#check value counts after oversampling\n",
        "y_train_series.value_counts()"
      ],
      "metadata": {
        "id": "H9B3eyPpVfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building PD Model (White-Box)"
      ],
      "metadata": {
        "id": "kpQBOfI5VfgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#building logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_o, y_train_o)"
      ],
      "metadata": {
        "id": "xcsTvM8wVfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting\n",
        "y_preds = model.predict(X_test)\n",
        "#classification report\n",
        "print(classification_report(y_test, y_preds))"
      ],
      "metadata": {
        "id": "kzJKDpSZVfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_test_proba = model.predict_proba(X_test)\n",
        "y_hat_test_proba = y_hat_test_proba[:][: , 1]\n",
        "y_test_temp = y_test.copy()\n",
        "y_test_temp.reset_index(drop = True, inplace = True)\n",
        "y_test_proba = pd.concat([y_test_temp, pd.DataFrame(y_hat_test_proba), pd.DataFrame(y_preds)], axis = 1)\n",
        "y_test_proba.columns = ['y_test_class_actual', 'y_hat_test_proba', 'y_hat_test']\n",
        "y_test_proba.index = X_test.index\n",
        "y_test_proba.head()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "eHT6svH9VfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assessing Discriminatory Power of the PD Model\n",
        "\n",
        "**1 A. ROC Curve**"
      ],
      "metadata": {
        "id": "2-r11IFeVfgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the values required to plot a ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
        "# plot the ROC curve\n",
        "plt.plot(fpr, tpr)\n",
        "# plot a secondary diagonal line, to plot randomness of model\n",
        "plt.plot(fpr, fpr, linestyle = '--', color = 'k')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve');"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "pzzS7i9aVfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 B. Area under ROC Curve**"
      ],
      "metadata": {
        "id": "T9jsG6xKVfgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Area under receiver operating charateristic cure\n",
        "AUROC = roc_auc_score(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
        "AUROC"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "jyghqQY7VfgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Gini Index**"
      ],
      "metadata": {
        "id": "DyT_tjH6VfgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gini = AUROC * 2 - 1\n",
        "Gini"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "umU_s6rwVfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3A. Precision-Recall Curve**\n",
        "\n",
        "If you want to know the details what is meant by **\"No-Skill PR Curve\"**, follow [this link](https://analyticsindiamag.com/complete-guide-to-understanding-precision-and-recall-curves/)"
      ],
      "metadata": {
        "id": "z-QaSmQfVfgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "# calculate the no skill line as the proportion of the positive class\n",
        "no_skill = len(y_test[y_test == 1]) / len(y)\n",
        "# plot the no skill precision-recall curve\n",
        "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
        "\n",
        "# calculate inputs for the PR curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_test_proba['y_test_class_actual'], y_test_proba['y_hat_test_proba'])\n",
        "# plot PR curve\n",
        "plt.plot(recall, precision, marker='.', label='Logistic')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend()\n",
        "plt.title('PR curve');"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "j7gmOEg1VfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3 B. Precision-Recall Score**"
      ],
      "metadata": {
        "id": "ZfDNlAPfVfgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#precision recall score\n",
        "auc_pr = auc(recall, precision)\n",
        "auc_pr"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "SDPc__sIVfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Kolmogorov-Smirnov Statistic**"
      ],
      "metadata": {
        "id": "ieMFTzjJVfgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calcualting ks statistic\n",
        "actual_predicted_probs_df = y_test_proba.sort_values('y_hat_test_proba')\n",
        "actual_predicted_probs_df = actual_predicted_probs_df.reset_index()\n",
        "actual_predicted_probs_df['cum_n_pop'] = actual_predicted_probs_df.index +1\n",
        "actual_predicted_probs_df['cum_good'] = actual_predicted_probs_df['y_test_class_actual'].cumsum()\n",
        "actual_predicted_probs_df['cum_bad'] = actual_predicted_probs_df['cum_n_pop'] - actual_predicted_probs_df['y_test_class_actual'].cumsum()\n",
        "actual_predicted_probs_df['cum_n_%'] = actual_predicted_probs_df['cum_n_pop']/(actual_predicted_probs_df.shape[0])\n",
        "actual_predicted_probs_df['cum_good_%'] = actual_predicted_probs_df['cum_good']/actual_predicted_probs_df['y_test_class_actual'].sum()\n",
        "actual_predicted_probs_df['cum_bad_%'] = actual_predicted_probs_df['cum_bad']/ (actual_predicted_probs_df.shape[0]-actual_predicted_probs_df['y_test_class_actual'].sum())\n",
        "plt.plot(actual_predicted_probs_df['cum_n_%'], actual_predicted_probs_df['cum_bad_%'])\n",
        "plt.plot(actual_predicted_probs_df['cum_n_%'], actual_predicted_probs_df['cum_n_%'], linestyle='--', c='k')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "i3GuoWo3VfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(actual_predicted_probs_df['y_hat_test_proba'], actual_predicted_probs_df['cum_bad_%'], c='r')\n",
        "plt.plot(actual_predicted_probs_df['y_hat_test_proba'], actual_predicted_probs_df['cum_good_%'], c='g')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "YnxzpRpCVfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ks = max(actual_predicted_probs_df['cum_bad_%'] - actual_predicted_probs_df['cum_good_%'])\n",
        "print('The KS score is ',ks)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "iQ30ONiWVfgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the scores above indicate the created PD model is an efficient one to apply on new data for getting accurate prediction."
      ],
      "metadata": {
        "id": "RVnAdO43VfgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model"
      ],
      "metadata": {
        "id": "3WUV6qekVfgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'credit_risk_PD_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "laBkyKBCVfgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future Scope\n",
        "\n",
        "* In this part, only the white-box PD model is built. We used logistic regression which is explainable by p-values of the features.\n",
        "* [In Part-2](https://www.kaggle.com/code/chandrimad31/credit-risk-part-2-black-box-model-explainability?scriptVersionId=94776660), we will build some black-box PD models (non-explainable) and will use different libraries to know important features for model explainability."
      ],
      "metadata": {
        "id": "hql3HcceVfgO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X-nyI1p_VfgO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}